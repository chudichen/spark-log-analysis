# Spark用户行为日志分析

### 目录结构
/sql: 数据库初始化的表

### 用户session分析
每一次执行用户访问session分析模块，要抽取100个session。

session随机抽取：按照每个的每个小时的session数量，占当天session总数的比例，乘以每天要抽取的session数量，计算出每个小时要抽取的session数量；
然后每天每小时的session中，随机抽取出之前计算出来的数量的session。

### 热门Top10

计算出来通过筛选条件的那些session，他们访问过的所有品类（点击、下单、支付），按照各个品类的点击、下单和支付次数，降序排序，获取前10个品类，也就是筛选条件下的那一批session的top10热门品类；

点击、下单和支付次数：有限按照点击次数排序、如果点击次数相等，那么按照下单次数排序、如果下单次数相等，那么按照支付次数排序。

这个需求是很有意义的，因为这样，就可以让数据分析师、产品经理、公司高层，随时随地都可以看到自己感兴趣的那一批用户，最喜欢的10个品类，从而对自己公司和产品的定位有清晰的了解，并且可以更加深入了解自己的用户，优化调整公司战略。

二次排序：

如果我们就只是根据某一个字段进行排序，比如点击次数降序排序，那么就不是二次排序；二次排序，顾名思义，就是说，不只是根据一个字段进行一次排序，肯呢个是要根据多个字段，进行多次排序的，点击、下单和支付次数，依次进行排序，就是二次排序

sortByKey,默认情况下，它支持根据int、long等类型来进行排序，但是那样的话，key就只能呢个放一个字段粒，所以需要自定义